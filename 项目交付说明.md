# IR 2025 项目交付说明

## 项目概述

本项目是一个基于BERT双编码器的检索系统，用于在WebQ数据集上进行开放域问答的文档检索。

## 已完成的工作

### 1. 环境搭建 ✓

- **Conda环境**: `ir2025` (Python 3.9)
- **依赖安装**: 所有必需包已安装（详见requirements.txt）
- **GPU配置**: 支持CUDA，默认使用GPU 6

### 2. 核心代码实现 ✓

#### 数据处理
- `preprocess_data.py` - 数据预处理脚本
  - 加载Wikipedia语料库（75万+ passages）
  - 处理WebQ训练数据，生成正负样本对
  - 处理测试数据和验证数据
  - 输出格式化的pickle和TSV文件

#### 模型实现
- `retriever_model.py` - 双编码器模型
  - BiEncoder类：独立的Query和Passage编码器
  - InfoNCELoss：对比学习损失函数
  - Retriever类：检索和编码功能

- `retriever_dataset.py` - 数据集类
  - RetrievalDataset：训练和测试数据集
  - RetrievalCollator：数据整理函数

#### 训练和测试
- `train_simple.py` - 简化版训练脚本
  - 完整的训练循环
  - 验证集评估
  - 模型保存和最佳模型选择

- `test_simple.py` - 测试评估脚本
  - 在测试集上评估
  - 计算Hit@1, Hit@10, Hit@100
  - 生成提交格式的结果文件

### 3. 文档和脚本 ✓

- **README.md** - 完整的项目说明文档
- **QUICKSTART.md** - 快速开始指南
- **SETUP.md** - 环境配置说明
- **实验报告模板.md** - 实验报告写作模板
- **requirements.txt** - Python依赖列表
- **setup_env.sh** - 环境设置脚本
- **run.sh** - 一键运行脚本

### 4. 数据预处理 ✓

已生成的数据文件：
```
processed/
├── passages.pkl (476MB) - 语料库
├── train_triples.tsv (22KB) - 训练三元组（1000样本）
├── train_triples_qa.pkl (56KB) - 问题和答案映射
├── test_questions.pkl (8KB) - 测试问题
├── test_answers.pkl (9.2KB) - 测试答案
└── dev/ - 验证集
```

## 快速使用指南

### 步骤1: 激活环境

```bash
cd /home/tanyuqiao/IR_Project-main/data/IR_2025_Project
source setup_env.sh
```

### 步骤2: 运行完整流程

```bash
bash run.sh
```

这会自动完成：
1. 数据预处理（已完成）
2. 模型训练
3. 测试评估
4. 生成结果文件

### 步骤3: 查看结果

```bash
cat output/test_results/metrics.json
cat output/test_results/hit_at_k.txt
```

## 文件说明

### 核心Python文件

| 文件 | 功能 | 运行时间 |
|------|------|----------|
| `preprocess_data.py` | 数据预处理 | ~5分钟 |
| `train_simple.py` | 模型训练 | ~30分钟 (3 epochs) |
| `test_simple.py` | 测试评估 | ~30分钟 |

### 配置文件

| 文件 | 说明 |
|------|------|
| `requirements.txt` | Python依赖 |
| `setup_env.sh` | 环境设置 |
| `run.sh` | 一键运行 |

### 文档文件

| 文件 | 内容 |
|------|------|
| `README.md` | 完整文档 |
| `QUICKSTART.md` | 快速开始 |
| `SETUP.md` | 环境配置 |
| `实验报告模板.md` | 报告模板 |

## 代码特点

### 1. 模块化设计
- 数据处理、模型定义、训练、测试分离
- 易于维护和扩展

### 2. 即用型脚本
- 一键运行脚本 `run.sh`
- 自动环境设置 `setup_env.sh`

### 3. 完整的文档
- 从安装到运行的完整说明
- 实验报告写作模板
- 常见问题解答

### 4. 灵活的配置
- 支持自定义GPU选择
- 可调整的训练参数
- 相对路径自动检测

## 下一步建议

### 短期（立即运行）

1. **运行训练**:
   ```bash
   source setup_env.sh
   python train_simple.py
   ```

2. **运行测试**:
   ```bash
   python test_simple.py
   ```

3. **查看结果**:
   ```bash
   cat output/test_results/hetrics.json
   ```

### 中期（优化性能）

1. **增加训练数据**:
   - 修改 `preprocess_data.py` 中的 `max_samples=10000`

2. **增加训练轮数**:
   - 修改 `train_simple.py` 中的 `EPOCHS = 10`

3. **使用更大模型**:
   - 修改 `MODEL_NAME = 'bert-large-uncased'`

### 长期（加分项）

1. **Hard Negative Mining**
2. **模型蒸馏**
3. **数据增强**
4. **重排序模块**

## 提交材料清单

根据作业要求，需要提交：

### 1. 源代码 ✓
- 所有 `.py` 文件
- `run.sh` 运行脚本
- `requirements.txt` 依赖文件

### 2. 结果文件（待生成）
- `output/test_results/hit_at_k.txt` - **提交格式**
- `output/test_results/metrics.json` - 整体指标
- `output/test_results/detailed_results.json` - 详细结果

### 3. 实验报告（待撰写）
- 使用 `实验报告模板.md` 作为参考
- 填写实际运行结果
- 说明技术方案和实现细节

## 技术架构

```
Query → BERT Encoder → Query Vector
                              ↓
                         Similarity
                              ↓
Passage → BERT Encoder → Passage Vector

损失函数: InfoNCE (对比学习)
优化器: AdamW
学习率调度: Linear Warmup
评估指标: Hit@1, Hit@10, Hit@100
```

## 关键参数

### 训练参数
- **Batch Size**: 16
- **Epochs**: 3 (可调整)
- **Learning Rate**: 2e-5
- **Max Length**: 256 (passage), 128 (query)

### 模型参数
- **Model**: BERT-base-uncased
- **Hidden Size**: 768
- **Layers**: 12
- **Attention Heads**: 12

## 预期结果

根据类似的检索系统，预期性能：

- **Hit@1**: 20-40%
- **Hit@10**: 40-60%
- **Hit@100**: 60-80%

实际结果会根据训练数据和参数有所不同。

## 故障排查

### 问题1: 数据预处理很慢
**原因**: 需要读取75万+ passages
**解决**: 正常现象，约需5-10分钟

### 问题2: 训练时显存不足
**解决**:
```python
# 在train_simple.py中减小batch_size
BATCH_SIZE = 8  # 从16改为8
```

### 问题3: Hit@K结果不理想
**解决**:
- 增加训练epoch数
- 增加训练样本数
- 使用更大的预训练模型

## 联系和支持

如有问题：
1. 查看相关文档（README.md, QUICKSTART.md）
2. 检查错误信息
3. 联系课程助教

---

**最后更新**: 2025-12-24
**状态**: 环境已就绪，代码已完成，待运行测试
