# IR 2025 大作业实验报告

**小组成员**：[成员1姓名]、[成员2姓名]、[成员3姓名]、[成员4姓名]、[成员5姓名]
**提交日期**：2025年12月XX日

---

## 一、实现方案

### 1.1 任务概述

本项目在WebQ数据集上实现了一个基于双编码器（Bi-Encoder）的检索系统，用于开放域问答任务中的文档检索。

### 1.2 整体架构

采用`Retriever + Reader`架构中的检索器部分：

```
Query (问题)
    ↓
Question Encoder (BERT)
    ↓
Query Vector

Passage (文档)
    ↓
Passage Encoder (BERT)
    ↓
Passage Vector

计算相似度: Similarity = Query Vector · Passage Vector
检索Top-K文档
```

### 1.3 技术选型

- **预训练模型**: BERT-base-uncased
- **编码器架构**: 双编码器（独立编码query和passage）
- **损失函数**: InfoNCE（对比学习损失）
- **相似度计算**: 余弦相似度
- **优化器**: AdamW
- **学习率调度**: Linear Warmup

### 1.4 实现特点

1. **双编码器设计**: Query和Passage使用独立的BERT编码器，可以提前编码Passage加速检索
2. **对比学习**: 使用正负样本对训练，提升检索准确率
3. **提前编码**: 在训练前编码所有Passage，测试时只需编码Query
4. **Hit@K评估**: 支持多级评估指标（Hit@1, Hit@10, Hit@100）

---

## 二、代码说明

### 2.1 主要文件结构

```
IR_Project-main/data/IR_2025_Project/
├── preprocess_data.py      # 数据预处理脚本
├── retriever_model.py      # 双编码器模型定义
├── retriever_dataset.py    # 数据集类
├── train_simple.py         # 训练脚本（简化版）
├── test_simple.py          # 测试脚本（简化版）
├── run.sh                  # 一键运行脚本
└── README.md               # 项目说明文档
```

### 2.2 核心类和函数

#### 2.2.1 BiEncoder类 (`retriever_model.py`)

```python
class BiEncoder(nn.Module):
    def __init__(self, model_name='bert-base-uncased'):
        # 初始化两个独立的BERT编码器

    def forward(self, question_ids, question_mask, passage_ids, passage_mask):
        # 返回query和passage的向量表示
```

**功能**: 双编码器模型，分别编码query和passage

#### 2.2.2 InfoNCELoss类 (`retriever_model.py`)

```python
class InfoNCELoss(nn.Module):
    def forward(self, query_vecs, passage_vecs):
        # 计算对比学习损失
```

**功能**: 计算对比学习损失，拉近query与正样本passage的距离

#### 2.2.3 数据预处理 (`preprocess_data.py`)

主要函数：
- `load_corpus()`: 加载Wikipedia语料库
- `process_webq_train()`: 处理训练数据，生成正负样本对
- `process_webq_test()`: 处理测试数据

#### 2.2.4 训练流程 (`train_simple.py`)

主函数 `main()` 包含：
1. 加载数据和tokenizer
2. 创建模型和优化器
3. 训练循环（多个epoch）
4. 验证集评估
5. 保存最佳模型

#### 2.2.5 测试评估 (`test_simple.py`)

主要函数：
- `evaluate_and_save_results()`: 在测试集上评估并保存结果
- `check_answer_in_passage()`: 检查答案是否在passage中

### 2.3 运行方法

#### 一键运行（推荐）
```bash
cd /home/tanyuqiao/IR_Project-main/data/IR_2025_Project
bash run.sh
```

#### 分步运行

1. **数据预处理**
```bash
python preprocess_data.py
```

2. **训练模型**
```bash
python train_simple.py
```

3. **测试评估**
```bash
python test_simple.py
```

### 2.4 输出文件

训练阶段：
- `output/retriever/best_model.pt` - 最佳模型
- `output/retriever/checkpoint_*.pt` - 检查点

测试阶段：
- `output/test_results/metrics.json` - Hit@K指标
- `output/test_results/hit_at_k.txt` - 提交格式结果
- `output/test_results/detailed_results.json` - 详细结果

---

## 三、技术原理

### 3.1 BERT编码器

BERT（Bidirectional Encoder Representations from Transformers）是一个预训练的语言表示模型：

- **输入**: Token序列 `[CLS] Question [SEP] Passage [SEP]`
- **输出**: 每个token的上下文表示向量
- **[CLS] Token**: 用于分类任务的聚合表示

本项目使用BERT的[CLS] token输出作为query/passage的向量表示。

### 3.2 双编码器架构

**优势**:
1. Query和Passage独立编码，可并行处理
2. Passage可提前编码并缓存，加速检索
3. 适合大规模检索场景

**公式**:
```
Q = BERT_question(q)
P = BERT_question(p)

sim(Q, P) = Q · P / (||Q|| × ||P||)
```

### 3.3 InfoNCE损失

对比学习损失，用于训练检索模型：

```
L = -log[exp(sim(q, p+)/τ) / Σ exp(sim(q, p)/τ)]
```

其中：
- `q`: query向量
- `p+`: 正样本passage向量
- `p-`: 负样本passage向量
- `τ`: 温度参数（默认0.05）

**目标**: 拉近query与正样本的距离，推远与负样本的距离。

### 3.4 Hit@K评估指标

对于每个query：
1. 检索top-K个passages
2. 检查答案是否在这K个passages中
3. 如果存在：Hit@K = 1，否则：Hit@K = 0

整体准确率：
```
Hit@K = (Σ Hit@K_i) / N
```

其中N为query总数。

---

## 四、实验步骤

### 4.1 数据处理

#### 训练数据
- **源数据**: `webq-train.json` (3718个问题)
- **处理流程**:
  1. 提取问题和答案
  2. 在语料库中匹配包含答案的passage作为正样本
  3. 随机选择不包含答案的passage作为负样本
  4. 生成训练三元组 `(query, positive_passage, negative_passage)`
  5. 限制最大样本数为10000（可调整）

#### 验证数据
- 从测试集中随机选择100个查询作为验证集
- 用于训练过程中调优参数

#### 测试数据
- **源数据**: `webq-test.csv` (2030个问题)
- **处理**: 直接加载问题和答案列表

#### 语料库
- **源数据**: `wiki_webq_corpus.tsv` (5,180,525个Wikipedia文档)
- **格式**: `id | text | title`

### 4.2 模型训练

#### 训练配置
```python
Model: BERT-base-uncased
Batch Size: 8
Learning Rate: 2e-5
Epochs: 5
Optimizer: AdamW
Scheduler: Linear Warmup
Max Length: 256 (passage), 128 (query)
```

#### 训练流程
1. **前向传播**: 编码query、正样本passage、负样本passage
2. **计算损失**: InfoNCE loss
3. **反向传播**: 更新模型参数
4. **验证**: 每个epoch后在验证集上评估Hit@K
5. **保存**: 保存Hit@10最高的模型

#### 关键代码
```python
# 前向传播
q_vec, pos_vec = model(question_ids, question_mask, pos_ids, pos_mask)
_, neg_vec = model(question_ids, question_mask, neg_ids, neg_mask)

# 计算损失
loss = contrastive_loss(q_vec, pos_vec, neg_vec)

# 反向传播
optimizer.zero_grad()
loss.backward()
optimizer.step()
```

### 4.3 模型验证

**验证集**: 从测试集中抽取的100个查询

**验证方法**:
1. 加载训练过程中的模型
2. 编码所有passages
3. 对每个验证query检索top-100
4. 计算Hit@1, Hit@10, Hit@100
5. 选择Hit@10最高的模型作为最终模型

**重要**: 验证集仅用于模型选择，不参与训练。

### 4.4 模型测试

**测试集**: 200个测试查询（实际2030个，按要求使用200个）

**测试流程**:
1. 加载最佳模型 `best_model.pt`
2. 编码所有passages（只做一次）
3. 对每个测试query：
   - 编码query
   - 计算与所有passages的相似度
   - 检索top-100
   - 检查答案是否在top-K中
4. 计算整体Hit@K指标
5. 保存结果到文件

**确保未在测试集上训练**: 测试集仅用于最终评估，不参与任何训练或参数调整。

---

## 五、结果汇报

### 5.1 测试集结果

在200个测试查询上的检索性能：

| 指标 | 数值 |
|------|------|
| **Hit@1**   | [待填写] |
| **Hit@10**  | [待填写] |
| **Hit@100** | [待填写] |

### 5.2 结果分析

1. **Hit@1**: [分析说明]
2. **Hit@10**: [分析说明]
3. **Hit@100**: [分析说明]

### 5.3 错误分析

[对典型错误案例进行分析]

### 5.4 对比实验

[如果有不同配置的对比，在此说明]

---

## 六、总结与展望

### 6.1 工作总结

1. 实现了基于BERT双编码器的检索系统
2. 在WebQ数据集上达到了XX%的Hit@10准确率
3. 完成了完整的数据处理、训练、验证、测试流程

### 6.2 改进方向

1. **Hard Negative Mining**: 使用难负样本提升训练效果
2. **模型改进**: 尝试更大的预训练模型（如RoBERTa、DPR）
3. **数据增强**: 对query进行改写增强
4. **重排序**: 使用交叉编码器对检索结果重排序
5. **集成学习**: 结合多个检索器的结果

### 6.3 心得体会

[填写项目过程中的心得体会]

---

## 参考文献

1. Devlin, J., et al. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.
2. Karpukhin, V., et al. (2020). Dense Passage Retrieval for Open-Domain Question Answering.
3. Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations.

---

## 附录

### A. 环境配置

```bash
# Python 3.7+
pip install torch==1.8.0
pip install transformers==4.0.0
pip install tqdm
```

### B. 运行示例

```bash
# 完整流程
cd /home/tanyuqiao/IR_Project-main/data/IR_2025_Project
bash run.sh

# 查看结果
cat output/test_results/metrics.json
cat output/test_results/hit_at_k.txt
```

### C. 提交材料清单

1. 源代码：`*.py`
2. 运行脚本：`run.sh`
3. 结果文件：`output/test_results/hit_at_k.txt`
4. 实验报告：本文档（PDF格式）
